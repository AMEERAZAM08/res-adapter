task: "controlnet"
sub_task: "image_to_image"
experiment_name: ""


# Model Configs
personalized_model: "/mnt/bn/automl-aigc/chengjiaxiang/models/diffusers/stable-diffusion-xl-base-1.0"
model_type: "sdxl"
controlnet_model: "/mnt/bn/automl-aigc/chengjiaxiang/models/diffusers/controlnet-canny-sdxl-1.0"
res_adapter_model: "/mnt/bn/automl-aigc/chengjiaxiang/python/res-adapter/models/res_adapter/sdxl-i"
res_adapter_alpha: 1.0


# Inference Configs
width: null
height: null
scale_ratio: 0.6  # scale the original image

num_inference_steps: 25
guidance_scale: 7.5
num_images_per_prompt: 8

source_images: [
  "assets/controlnet/man.png",
  # "assets/controlnet/old.png",
]

prompts: [
  "man",
  # "old man",
]

n_prompt: "lowres, bad anatomy, worst quality, low quality"


# Other Configs
enable_xformers: true
enable_compare: true
draw_text: false
seed: 42
device: 0
split_images: true